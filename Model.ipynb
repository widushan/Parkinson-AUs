{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ea82826",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix, log_loss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da987e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2b0be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Training and Evaluation ---\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"face_mimic_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e280aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "features = ['AU_01_t12', 'AU_06_t12', 'AU_12_t12', 'AU_04_t13', 'AU_07_t13', \n",
    "            'AU_09_t13', 'AU_01_t14', 'AU_02_t14', 'AU_04_t14', 'age', 'gender']\n",
    "X = df[features].dropna()\n",
    "y = df.loc[X.index, 'diagnosed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d007a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0405e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32e2aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15aa1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1': 'f1',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'roc_auc': 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "960a88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to compute log loss and accuracies\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_losses, val_losses = [], []\n",
    "y_true_val, y_pred_val, y_pred_proba_val = [], [], []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X_resampled, y_resampled):\n",
    "    X_train, X_val = X_resampled[train_idx], X_resampled[val_idx]\n",
    "    y_train, y_val = y_resampled[train_idx], y_resampled[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = rf_model.predict(X_train)\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "    y_train_proba = rf_model.predict_proba(X_train)\n",
    "    y_val_proba = rf_model.predict_proba(X_val)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    train_accuracies.append(accuracy_score(y_train, y_train_pred))\n",
    "    val_accuracies.append(accuracy_score(y_val, y_val_pred))\n",
    "    \n",
    "    # Compute log loss (proxy for loss)\n",
    "    train_losses.append(log_loss(y_train, y_train_proba))\n",
    "    val_losses.append(log_loss(y_val, y_val_proba))\n",
    "    \n",
    "    # Store validation predictions for AUPRC and confusion matrix\n",
    "    y_true_val.extend(y_val)\n",
    "    y_pred_val.extend(y_val_pred)\n",
    "    y_pred_proba_val.extend(y_val_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d79a7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute AUPRC for validation data\n",
    "precision, recall, _ = precision_recall_curve(y_true_val, y_pred_proba_val)\n",
    "auprc = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "176b627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (SMOTE-balanced data):\n",
      "Mean Training Accuracy: 1.0000 (±0.0000)\n",
      "Mean Validation Accuracy: 0.9271 (±0.0183)\n",
      "Mean Training Log Loss: 0.0745 (±0.0016)\n",
      "Mean Validation Log Loss: 0.2380 (±0.0144)\n",
      "Mean F1 Score: 0.9294\n",
      "Mean Precision: 0.9049\n",
      "Mean Recall: 0.9563\n",
      "Mean ROC AUC: 0.9850\n",
      "AUPRC: 0.9845\n"
     ]
    }
   ],
   "source": [
    "# Print cross-validation results\n",
    "print(\"Cross-Validation Results (SMOTE-balanced data):\")\n",
    "print(f\"Mean Training Accuracy: {np.mean(train_accuracies):.4f} (±{np.std(train_accuracies):.4f})\")\n",
    "print(f\"Mean Validation Accuracy: {np.mean(val_accuracies):.4f} (±{np.std(val_accuracies):.4f})\")\n",
    "print(f\"Mean Training Log Loss: {np.mean(train_losses):.4f} (±{np.std(train_losses):.4f})\")\n",
    "print(f\"Mean Validation Log Loss: {np.mean(val_losses):.4f} (±{np.std(val_losses):.4f})\")\n",
    "print(f\"Mean F1 Score: {np.mean(cross_validate(rf_model, X_resampled, y_resampled, cv=cv, scoring='f1')['test_score']):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(cross_validate(rf_model, X_resampled, y_resampled, cv=cv, scoring='precision')['test_score']):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(cross_validate(rf_model, X_resampled, y_resampled, cv=cv, scoring='recall')['test_score']):.4f}\")\n",
    "print(f\"Mean ROC AUC: {np.mean(cross_validate(rf_model, X_resampled, y_resampled, cv=cv, scoring='roc_auc')['test_score']):.4f}\")\n",
    "print(f\"AUPRC: {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24c1e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on original (imbalanced) dataset\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "y_pred_original = rf_model.predict(X_scaled)\n",
    "y_pred_proba_original = rf_model.predict_proba(X_scaled)[:, 1]\n",
    "precision_orig, recall_orig, _ = precision_recall_curve(y, y_pred_proba_original)\n",
    "auprc_orig = auc(recall_orig, precision_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50ab134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on Original (Imbalanced) Data:\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "AUPRC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerformance on Original (Imbalanced) Data:\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_original):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred_original):.4f}\")\n",
    "print(f\"Precision: {precision_score(y, y_pred_original):.4f}\")\n",
    "print(f\"Recall: {recall_score(y, y_pred_original):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y, y_pred_proba_original):.4f}\")\n",
    "print(f\"AUPRC: {auprc_orig:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41b4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 6), train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(range(1, 6), val_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('accuracy_plot.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28997c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 6), train_losses, label='Training Log Loss', marker='o')\n",
    "plt.plot(range(1, 6), val_losses, label='Validation Log Loss', marker='o')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('Training and Validation Log Loss Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_plot.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be88557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix (Original Data)\n",
    "cm = confusion_matrix(y, y_pred_original)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Healthy', 'PD'], yticklabels=['Healthy', 'PD'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Original Imbalanced Data)')\n",
    "plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03305027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scaler for real-time use\n",
    "with open('rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c321e6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.21\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfbb585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Real-Time AU Extraction and Prediction ---\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, \n",
    "                                  min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7dfca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d6821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for AU extraction (simplified, as MediaPipe doesn't directly provide FACS AUs)\n",
    "def extract_au_features(landmarks):\n",
    "    if not landmarks:\n",
    "        return np.zeros(9)  # Return zeros if no face detected\n",
    "    \n",
    "    # Example landmark indices (MediaPipe Face Mesh 468-point model)\n",
    "    left_eye = landmarks.landmark[159]  # Upper eyelid\n",
    "    left_brow = landmarks.landmark[70]  # Inner eyebrow\n",
    "    right_eye = landmarks.landmark[386]\n",
    "    right_brow = landmarks.landmark[300]\n",
    "    cheek_left = landmarks.landmark[205]\n",
    "    lip_corner_left = landmarks.landmark[61]\n",
    "    lip_corner_right = landmarks.landmark[291]\n",
    "    outer_brow_left = landmarks.landmark[66]\n",
    "    \n",
    "    # AU_01: Inner brow raiser\n",
    "    au_01 = np.mean([np.abs(left_brow.y - left_eye.y), np.abs(right_brow.y - right_eye.y)])\n",
    "    # AU_06: Cheek raiser\n",
    "    au_06 = np.abs(cheek_left.y - left_eye.y)\n",
    "    # AU_12: Lip corner puller\n",
    "    au_12 = np.mean([np.abs(lip_corner_left.x - lip_corner_right.x)])\n",
    "    # AU_04: Brow lowerer\n",
    "    au_04 = np.abs(left_brow.y - right_brow.y)\n",
    "    # AU_07: Lid tightener\n",
    "    au_07 = np.abs(left_eye.y - landmarks.landmark[145].y)\n",
    "    # AU_09: Nose wrinkler (placeholder)\n",
    "    au_09 = 0.0\n",
    "    # AU_02: Outer brow raiser\n",
    "    au_02 = np.abs(outer_brow_left.y - left_eye.y)\n",
    "    \n",
    "    return np.array([au_01, au_06, au_12, au_04, au_07, au_09, au_01, au_02, au_04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time prediction\n",
    "au_buffer = []  # Buffer to store AU features\n",
    "max_buffer_size = 150  # ~5 seconds at 30 fps\n",
    "user_age = 60  # Placeholder\n",
    "user_gender = 1  # Placeholder (1=male, 0=female)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to RGB for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    \n",
    "    # Extract AU features\n",
    "    au_features = np.zeros(9)\n",
    "    if results.multi_face_landmarks:\n",
    "        au_features = extract_au_features(results.multi_face_landmarks[0])\n",
    "    \n",
    "    # Append to buffer\n",
    "    au_buffer.append(au_features)\n",
    "    if len(au_buffer) > max_buffer_size:\n",
    "        au_buffer.pop(0)\n",
    "    \n",
    "    # Compute average AU features and predict\n",
    "    if len(au_buffer) >= max_buffer_size:\n",
    "        avg_au = np.mean(au_buffer, axis=0)\n",
    "        input_features = np.append(avg_au, [user_age, user_gender])\n",
    "        input_scaled = scaler.transform([input_features])\n",
    "        \n",
    "        # Predict PD status\n",
    "        pred = rf_model.predict(input_scaled)[0]\n",
    "        pred_proba = rf_model.predict_proba(input_scaled)[0][1]\n",
    "        \n",
    "        # Display result on frame\n",
    "        label = \"PD\" if pred == 1 else \"Healthy\"\n",
    "        color = (0, 0, 255) if pred == 1 else (0, 255, 0)\n",
    "        cv2.putText(frame, f\"Status: {label} ({pred_proba:.2f})\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    \n",
    "    # Show frame\n",
    "    cv2.imshow('PD Detection', frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "259191fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "face_mesh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb35d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save AU buffer for debugging\n",
    "np.save('au_buffer.npy', np.array(au_buffer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
